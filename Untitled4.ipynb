{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "1JmK6hkTDgxZ8XeUB4urtlbJ6Im_YpJOd",
      "authorship_tag": "ABX9TyPp/KeI/Zgm99x5pSgCyTMZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ayushpgs/C-program/blob/main/Untitled4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "OMqv0E6MNOt_"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import tensorflow as tf\n",
        "\n",
        "# Load data\n",
        "train_df = pd.read_csv('/train.csv')\n",
        "test_df = pd.read_csv('/test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "#  Check missing values in both datasets\n",
        "print(\"Missing values in train dataset:\\n\", train_df.isnull().sum()[train_df.isnull().sum() > 0])\n",
        "print(\"\\nMissing values in test dataset:\\n\", test_df.isnull().sum()[test_df.isnull().sum() > 0])\n",
        "\n",
        "\n",
        "\n",
        "#  Drop columns with too many missing values (optional, for very sparse columns)\n",
        "drop_columns = ['Alley', 'PoolQC', 'Fence', 'MiscFeature']\n",
        "\n",
        "# Only drop columns if they exist in the dataset\n",
        "train_df.drop([col for col in drop_columns if col in train_df], axis=1, inplace=True)\n",
        "test_df.drop([col for col in drop_columns if col in test_df], axis=1, inplace=True)\n",
        "\n",
        "#  Impute missing values for numerical features with the median\n",
        "numerical_features = ['LotFrontage', 'MasVnrArea', 'GarageYrBlt']\n",
        "\n",
        "imputer_num = SimpleImputer(strategy='median')\n",
        "# Fit on the training data and transform both train and test data\n",
        "train_df[numerical_features] = imputer_num.fit_transform(train_df[numerical_features])\n",
        "test_df[numerical_features] = imputer_num.transform(test_df[numerical_features])\n",
        "\n",
        "#  Impute missing values for categorical features with the most frequent category\n",
        "categorical_features = ['MasVnrType', 'BsmtQual', 'BsmtCond', 'BsmtExposure',\n",
        "                        'BsmtFinType1', 'BsmtFinType2', 'Electrical',\n",
        "                        'FireplaceQu', 'GarageType', 'GarageFinish',\n",
        "                        'GarageQual', 'GarageCond']\n",
        "\n",
        "imputer_cat = SimpleImputer(strategy='most_frequent')\n",
        "\n",
        "# Fit on the training data and transform both train and test data\n",
        "train_df[categorical_features] = imputer_cat.fit_transform(train_df[categorical_features])\n",
        "test_df[categorical_features] = imputer_cat.transform(test_df[categorical_features])\n",
        "print(\"\\nMissing values in train dataset after imputation:\\n\", train_df.isnull().sum()[train_df.isnull().sum() > 0])\n",
        "print(\"\\nMissing values in test dataset after imputation:\\n\", test_df.isnull().sum()[test_df.isnull().sum() > 0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FhkP-denNpmw",
        "outputId": "6f07a9b9-40d2-4751-b37b-4a3ddd899935"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing values in train dataset:\n",
            " LotFrontage      259\n",
            "Alley           1369\n",
            "MasVnrType       872\n",
            "MasVnrArea         8\n",
            "BsmtQual          37\n",
            "BsmtCond          37\n",
            "BsmtExposure      38\n",
            "BsmtFinType1      37\n",
            "BsmtFinType2      38\n",
            "Electrical         1\n",
            "FireplaceQu      690\n",
            "GarageType        81\n",
            "GarageYrBlt       81\n",
            "GarageFinish      81\n",
            "GarageQual        81\n",
            "GarageCond        81\n",
            "PoolQC          1453\n",
            "Fence           1179\n",
            "MiscFeature     1406\n",
            "dtype: int64\n",
            "\n",
            "Missing values in test dataset:\n",
            " MSZoning           4\n",
            "LotFrontage      227\n",
            "Alley           1352\n",
            "Utilities          2\n",
            "Exterior1st        1\n",
            "Exterior2nd        1\n",
            "MasVnrType       894\n",
            "MasVnrArea        15\n",
            "BsmtQual          44\n",
            "BsmtCond          45\n",
            "BsmtExposure      44\n",
            "BsmtFinType1      42\n",
            "BsmtFinSF1         1\n",
            "BsmtFinType2      42\n",
            "BsmtFinSF2         1\n",
            "BsmtUnfSF          1\n",
            "TotalBsmtSF        1\n",
            "BsmtFullBath       2\n",
            "BsmtHalfBath       2\n",
            "KitchenQual        1\n",
            "Functional         2\n",
            "FireplaceQu      730\n",
            "GarageType        76\n",
            "GarageYrBlt       78\n",
            "GarageFinish      78\n",
            "GarageCars         1\n",
            "GarageArea         1\n",
            "GarageQual        78\n",
            "GarageCond        78\n",
            "PoolQC          1456\n",
            "Fence           1169\n",
            "MiscFeature     1408\n",
            "SaleType           1\n",
            "dtype: int64\n",
            "\n",
            "Missing values in train dataset after imputation:\n",
            " Series([], dtype: int64)\n",
            "\n",
            "Missing values in test dataset after imputation:\n",
            " MSZoning        4\n",
            "Utilities       2\n",
            "Exterior1st     1\n",
            "Exterior2nd     1\n",
            "BsmtFinSF1      1\n",
            "BsmtFinSF2      1\n",
            "BsmtUnfSF       1\n",
            "TotalBsmtSF     1\n",
            "BsmtFullBath    2\n",
            "BsmtHalfBath    2\n",
            "KitchenQual     1\n",
            "Functional      2\n",
            "GarageCars      1\n",
            "GarageArea      1\n",
            "SaleType        1\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "remaining_numeric_features = ['BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF',\n",
        "                              'BsmtFullBath', 'BsmtHalfBath', 'GarageCars', 'GarageArea']\n",
        "remaining_categorical_features = ['MSZoning', 'Utilities', 'Exterior1st', 'Exterior2nd',\n",
        "                                  'KitchenQual', 'Functional', 'SaleType']\n",
        "\n",
        "# Impute missing numeric features in the test dataset with median\n",
        "test_df[remaining_numeric_features] = imputer_num.fit_transform(test_df[remaining_numeric_features])\n",
        "\n",
        "# Impute missing categorical features in the test dataset with most frequent value\n",
        "test_df[remaining_categorical_features] = imputer_cat.fit_transform(test_df[remaining_categorical_features])\n",
        "\n",
        "# Check if any missing values remain in the test dataset\n",
        "print(\"\\nMissing values in test dataset after additional imputation:\\n\", test_df.isnull().sum()[test_df.isnull().sum() > 0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eDgwJYVWOSXy",
        "outputId": "24b83b24-8842-4b32-ebd4-4ad64e2e7f76"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Missing values in test dataset after additional imputation:\n",
            " Series([], dtype: int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "categorical_columns = train_df.select_dtypes(include=['object']).columns\n",
        "\n",
        "# Use Label Encoding for categorical features\n",
        "for col in categorical_columns:\n",
        "    le = LabelEncoder()\n",
        "    train_df[col] = le.fit_transform(train_df[col])\n",
        "    test_df[col] = le.transform(test_df[col])"
      ],
      "metadata": {
        "id": "-zBkb022OSUW"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_column = 'SalePrice'\n",
        "X_train = train_df.drop(columns=[target_column])\n",
        "y_train = train_df[target_column]\n",
        "\n",
        "# Ensure the same columns are present in both train and test datasets\n",
        "numeric_columns = X_train.select_dtypes(include=['int64', 'float64']).columns\n",
        "\n",
        "# Initialize the scaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Scale only the numeric features in both training and test sets\n",
        "X_train[numeric_columns] = scaler.fit_transform(X_train[numeric_columns])\n",
        "test_df[numeric_columns] = scaler.transform(test_df[numeric_columns])\n"
      ],
      "metadata": {
        "id": "5V0al2RFSNvM"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna xgboost lightgbm catboost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uCKqhW1YQSaJ",
        "outputId": "ae001acd-30a3-4df2-a32e-2f8f4b11c15a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: optuna in /usr/local/lib/python3.10/dist-packages (4.0.0)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.10/dist-packages (2.1.1)\n",
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.10/dist-packages (4.5.0)\n",
            "Requirement already satisfied: catboost in /usr/local/lib/python3.10/dist-packages (1.2.7)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (1.13.3)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.10/dist-packages (from optuna) (6.8.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (24.1)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.35)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.66.5)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.10/dist-packages (from xgboost) (2.23.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.13.1)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost) (0.20.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from catboost) (3.7.1)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.10/dist-packages (from catboost) (2.1.4)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost) (1.16.0)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (1.3.5)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2024.1)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna) (3.1.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.4.7)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (3.1.4)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost) (9.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.1.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "print(xgb.__version__)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jFrtQpuUZJP0",
        "outputId": "f5ea200c-af19-47dc-d4ab-7f1c2694b52e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import pandas as pd\n",
        "\n",
        "# Assuming X_train and y_train are already defined and preprocessed\n",
        "\n",
        "# Split the training data into training and validation sets\n",
        "X_train_split, X_valid, y_train_split, y_valid = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the objective function for XGBoost\n",
        "def objective_xgboost(trial):\n",
        "    param = {\n",
        "        'verbosity': 0,\n",
        "        'objective': 'reg:squarederror',\n",
        "        'booster': trial.suggest_categorical('booster', ['gbtree', 'dart']),\n",
        "        'lambda': trial.suggest_float('lambda', 1e-8, 10.0, log=True),\n",
        "        'alpha': trial.suggest_float('alpha', 1e-8, 10.0, log=True),\n",
        "        'subsample': trial.suggest_float('subsample', 0.4, 1.0),\n",
        "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.4, 1.0),\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 100, 500),\n",
        "        'max_depth': trial.suggest_int('max_depth', 3, 7),\n",
        "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
        "        'gamma': trial.suggest_float('gamma', 1e-8, 10.0, log=True),\n",
        "    }\n",
        "\n",
        "    # Convert to DMatrix format\n",
        "    dtrain = xgb.DMatrix(X_train_split, label=y_train_split)\n",
        "    dvalid = xgb.DMatrix(X_valid, label=y_valid)\n",
        "\n",
        "    # Train the model with early stopping\n",
        "    evals = [(dtrain, 'train'), (dvalid, 'valid')]\n",
        "\n",
        "    model = xgb.train(params=param, dtrain=dtrain, num_boost_round=500,\n",
        "                      evals=evals, early_stopping_rounds=50, verbose_eval=False)\n",
        "\n",
        "    # Make predictions on the validation set\n",
        "    preds = model.predict(dvalid)\n",
        "    mse = mean_squared_error(y_valid, preds)\n",
        "\n",
        "    return mse\n",
        "\n",
        "# Create and run the Optuna study\n",
        "study_xgboost = optuna.create_study(direction='minimize')\n",
        "study_xgboost.optimize(objective_xgboost, n_trials=20, timeout=600)\n",
        "\n",
        "# Get the best parameters and retrain the model\n",
        "best_params_xgboost = study_xgboost.best_params\n",
        "\n",
        "# Fit the model on the full training set\n",
        "final_dtrain = xgb.DMatrix(X_train, label=y_train)\n",
        "final_xgboost_model = xgb.train(params=best_params_xgboost, dtrain=final_dtrain, num_boost_round=500)\n",
        "\n",
        "# Make predictions on the test_df\n",
        "test_dmatrix = xgb.DMatrix(test_df)  # Ensure test_df is prepared similarly\n",
        "xgboost_predictions = final_xgboost_model.predict(test_dmatrix)\n",
        "\n",
        "# Optionally, save predictions to a CSV file\n",
        "submission_df = pd.DataFrame({'Id': test_df['Id'], 'SalePrice': xgboost_predictions})\n",
        "submission_df.to_csv('submission.csv', index=False)\n",
        "output_xgboost = pd.DataFrame({\n",
        "    'Id': test_df.index.astype('int32'),  # Ensure 'Id' is integer\n",
        "    'SalePrice': xgboost_predictions.flatten()\n",
        "})\n",
        "output_xgboost.to_csv('xgboost_predictions.csv', index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q57MGzrRdCCs",
        "outputId": "df3eca16-1e36-4660-c13d-715552d9898a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-09-30 19:49:33,785] A new study created in memory with name: no-name-220bedef-3dbb-4f43-9000-b3b80a5b74b1\n",
            "[I 2024-09-30 19:50:31,327] Trial 0 finished with value: 628211794.6985673 and parameters: {'booster': 'dart', 'lambda': 5.689155965727605e-07, 'alpha': 0.002840113908542828, 'subsample': 0.5711429886171111, 'colsample_bytree': 0.9197077127669728, 'learning_rate': 0.08882196303790904, 'n_estimators': 281, 'max_depth': 6, 'min_child_weight': 2, 'gamma': 0.386659163782805}. Best is trial 0 with value: 628211794.6985673.\n",
            "[I 2024-09-30 19:50:41,178] Trial 1 finished with value: 705399060.186711 and parameters: {'booster': 'dart', 'lambda': 0.0006763057355800345, 'alpha': 0.2532624823468575, 'subsample': 0.6216254387596174, 'colsample_bytree': 0.48844856590441904, 'learning_rate': 0.11135232252223107, 'n_estimators': 201, 'max_depth': 7, 'min_child_weight': 9, 'gamma': 1.0110837870523074e-07}. Best is trial 0 with value: 628211794.6985673.\n",
            "[I 2024-09-30 19:50:41,954] Trial 2 finished with value: 706862505.4317368 and parameters: {'booster': 'gbtree', 'lambda': 9.523191395893137e-05, 'alpha': 0.6413431628317112, 'subsample': 0.7138058304067982, 'colsample_bytree': 0.7177460791879673, 'learning_rate': 0.07537837723069173, 'n_estimators': 255, 'max_depth': 3, 'min_child_weight': 6, 'gamma': 1.950707749705689e-06}. Best is trial 0 with value: 628211794.6985673.\n",
            "[I 2024-09-30 19:51:03,929] Trial 3 finished with value: 632358750.448212 and parameters: {'booster': 'dart', 'lambda': 1.310201675610051e-07, 'alpha': 1.8763857070046534e-08, 'subsample': 0.7248886404409833, 'colsample_bytree': 0.733401744300243, 'learning_rate': 0.0721208627600099, 'n_estimators': 239, 'max_depth': 4, 'min_child_weight': 6, 'gamma': 1.144939090997048e-07}. Best is trial 0 with value: 628211794.6985673.\n",
            "[I 2024-09-30 19:51:04,352] Trial 4 finished with value: 715795374.1296357 and parameters: {'booster': 'gbtree', 'lambda': 0.4775753252429985, 'alpha': 0.002073298472059312, 'subsample': 0.61866299917247, 'colsample_bytree': 0.5818546185178981, 'learning_rate': 0.16532407864997536, 'n_estimators': 168, 'max_depth': 4, 'min_child_weight': 9, 'gamma': 1.7682270123057842}. Best is trial 0 with value: 628211794.6985673.\n",
            "[I 2024-09-30 19:51:07,442] Trial 5 finished with value: 1023799769.3302252 and parameters: {'booster': 'dart', 'lambda': 5.498699466499994e-07, 'alpha': 0.0026015038611082687, 'subsample': 0.42018900204915705, 'colsample_bytree': 0.7673833804534296, 'learning_rate': 0.2926013248350826, 'n_estimators': 224, 'max_depth': 3, 'min_child_weight': 6, 'gamma': 0.00018202586530256126}. Best is trial 0 with value: 628211794.6985673.\n",
            "[I 2024-09-30 19:51:09,370] Trial 6 finished with value: 626747361.7359486 and parameters: {'booster': 'gbtree', 'lambda': 0.023786597994697494, 'alpha': 0.9709711038136767, 'subsample': 0.4981605465057599, 'colsample_bytree': 0.6661344950501757, 'learning_rate': 0.07062124702180594, 'n_estimators': 462, 'max_depth': 4, 'min_child_weight': 3, 'gamma': 0.012823447825852388}. Best is trial 6 with value: 626747361.7359486.\n",
            "[I 2024-09-30 19:51:09,715] Trial 7 finished with value: 714209761.7270095 and parameters: {'booster': 'gbtree', 'lambda': 3.7532093506129702, 'alpha': 0.35835830526327456, 'subsample': 0.6300851514355589, 'colsample_bytree': 0.8125336916888877, 'learning_rate': 0.2719283465462297, 'n_estimators': 110, 'max_depth': 4, 'min_child_weight': 1, 'gamma': 0.006469329607790591}. Best is trial 6 with value: 626747361.7359486.\n",
            "[I 2024-09-30 19:51:10,039] Trial 8 finished with value: 825696836.0801178 and parameters: {'booster': 'gbtree', 'lambda': 4.850522372185869e-06, 'alpha': 3.1291643595054367e-07, 'subsample': 0.6993053316698287, 'colsample_bytree': 0.9472280224212648, 'learning_rate': 0.2695739535488497, 'n_estimators': 473, 'max_depth': 3, 'min_child_weight': 8, 'gamma': 7.630508567964123e-05}. Best is trial 6 with value: 626747361.7359486.\n",
            "[I 2024-09-30 19:51:10,339] Trial 9 finished with value: 943678438.8038491 and parameters: {'booster': 'gbtree', 'lambda': 9.244349423416097, 'alpha': 1.71246404915563e-07, 'subsample': 0.5893641711868748, 'colsample_bytree': 0.8467791695764408, 'learning_rate': 0.2102430491842948, 'n_estimators': 243, 'max_depth': 4, 'min_child_weight': 10, 'gamma': 2.0281105614579414e-08}. Best is trial 6 with value: 626747361.7359486.\n",
            "[I 2024-09-30 19:51:12,004] Trial 10 finished with value: 639828895.3749722 and parameters: {'booster': 'gbtree', 'lambda': 0.01458279519256566, 'alpha': 3.5557845985247654e-05, 'subsample': 0.9677796523795675, 'colsample_bytree': 0.5692912403240116, 'learning_rate': 0.01803336277066242, 'n_estimators': 429, 'max_depth': 5, 'min_child_weight': 3, 'gamma': 0.02337373229076294}. Best is trial 6 with value: 626747361.7359486.\n",
            "[I 2024-09-30 19:52:29,079] Trial 11 finished with value: 637883419.6481378 and parameters: {'booster': 'dart', 'lambda': 1.263443800665674e-08, 'alpha': 3.6546309927840657, 'subsample': 0.46120649673024217, 'colsample_bytree': 0.9872778470522653, 'learning_rate': 0.011592205298473914, 'n_estimators': 357, 'max_depth': 7, 'min_child_weight': 3, 'gamma': 8.539319410374391}. Best is trial 6 with value: 626747361.7359486.\n",
            "[I 2024-09-30 19:52:40,495] Trial 12 finished with value: 569204084.3505487 and parameters: {'booster': 'dart', 'lambda': 0.01427016077821831, 'alpha': 0.016618604102207876, 'subsample': 0.5042117025670625, 'colsample_bytree': 0.6343898091169652, 'learning_rate': 0.1205708570110543, 'n_estimators': 339, 'max_depth': 6, 'min_child_weight': 2, 'gamma': 0.10620353260133271}. Best is trial 12 with value: 569204084.3505487.\n",
            "[I 2024-09-30 19:52:51,647] Trial 13 finished with value: 701280289.8740569 and parameters: {'booster': 'dart', 'lambda': 0.027958671599024786, 'alpha': 0.042184696384055594, 'subsample': 0.49977224424787975, 'colsample_bytree': 0.6178173051354556, 'learning_rate': 0.1435267754581241, 'n_estimators': 365, 'max_depth': 6, 'min_child_weight': 4, 'gamma': 0.01598624644145252}. Best is trial 12 with value: 569204084.3505487.\n",
            "[I 2024-09-30 19:52:52,276] Trial 14 finished with value: 607289566.9007735 and parameters: {'booster': 'gbtree', 'lambda': 0.01142109459619629, 'alpha': 3.885278340011689e-05, 'subsample': 0.8654290427784026, 'colsample_bytree': 0.46895866094835514, 'learning_rate': 0.17412320572681259, 'n_estimators': 354, 'max_depth': 5, 'min_child_weight': 1, 'gamma': 0.11077471876127387}. Best is trial 12 with value: 569204084.3505487.\n",
            "[I 2024-09-30 19:52:54,620] Trial 15 finished with value: 749147069.7141194 and parameters: {'booster': 'dart', 'lambda': 0.0008559108325485657, 'alpha': 3.29227256210256e-05, 'subsample': 0.8687262646905722, 'colsample_bytree': 0.4263170179931631, 'learning_rate': 0.19541838596349884, 'n_estimators': 341, 'max_depth': 6, 'min_child_weight': 1, 'gamma': 0.0009128878061199822}. Best is trial 12 with value: 569204084.3505487.\n",
            "[I 2024-09-30 19:52:58,286] Trial 16 finished with value: 789395627.2550509 and parameters: {'booster': 'dart', 'lambda': 0.2780998159690007, 'alpha': 3.604459610277773e-05, 'subsample': 0.8376383771101404, 'colsample_bytree': 0.4608511202421252, 'learning_rate': 0.21046218861314234, 'n_estimators': 405, 'max_depth': 5, 'min_child_weight': 4, 'gamma': 0.12620332784876434}. Best is trial 12 with value: 569204084.3505487.\n",
            "[I 2024-09-30 19:52:59,007] Trial 17 finished with value: 734444952.4468337 and parameters: {'booster': 'gbtree', 'lambda': 5.848955889556856e-05, 'alpha': 1.6649949010400003e-06, 'subsample': 0.8144741326888252, 'colsample_bytree': 0.5155534898946251, 'learning_rate': 0.13110226666851327, 'n_estimators': 311, 'max_depth': 6, 'min_child_weight': 1, 'gamma': 1.2709169798584879e-05}. Best is trial 12 with value: 569204084.3505487.\n",
            "[I 2024-09-30 19:52:59,437] Trial 18 finished with value: 647345085.9416692 and parameters: {'booster': 'gbtree', 'lambda': 0.003794927169512607, 'alpha': 0.020132744471361704, 'subsample': 0.9911602089644954, 'colsample_bytree': 0.40025285414300094, 'learning_rate': 0.17522766745946516, 'n_estimators': 404, 'max_depth': 5, 'min_child_weight': 2, 'gamma': 0.25025851981461855}. Best is trial 12 with value: 569204084.3505487.\n",
            "[I 2024-09-30 19:53:05,104] Trial 19 finished with value: 690683454.8801723 and parameters: {'booster': 'dart', 'lambda': 0.12925625909998031, 'alpha': 0.0002773519113345883, 'subsample': 0.9235772395556027, 'colsample_bytree': 0.657754912697522, 'learning_rate': 0.2339246479385876, 'n_estimators': 311, 'max_depth': 5, 'min_child_weight': 5, 'gamma': 0.002000673501397782}. Best is trial 12 with value: 569204084.3505487.\n"
          ]
        }
      ]
    }
  ]
}